# -*- coding: utf-8 -*-
"""CNN_image.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i0Cg0Bf4Qm-vv4loT1E6J7VeHHX3vJaK
"""

import os
import torch
import torchvision
import tarfile
from torchvision.datasets.utils import download_url
from torch.utils.data import random_split

project_name='05-cifar10-cnn'

dataset_url = "https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz"
download_url(dataset_url, '.')

with tarfile.open('./cifar10.tgz', 'r:gz') as tar:
    def is_within_directory(directory, target):
        
        abs_directory = os.path.abspath(directory)
        abs_target = os.path.abspath(target)
    
        prefix = os.path.commonprefix([abs_directory, abs_target])
        
        return prefix == abs_directory
    
    def safe_extract(tar, path=".", members=None, *, numeric_owner=False):
    
        for member in tar.getmembers():
            member_path = os.path.join(path, member.name)
            if not is_within_directory(path, member_path):
                raise Exception("Attempted Path Traversal in Tar File")
    
        tar.extractall(path, members, numeric_owner=numeric_owner) 
        
    
    safe_extract(tar, path="./data")

data_dir = './data/cifar10'
print(os.listdir(data_dir))
classes = os.listdir(data_dir + "/train")
print(classes)

from torchvision.datasets import ImageFolder
from torchvision.transforms import ToTensor

dataset = ImageFolder(data_dir+'/train', transform=ToTensor())

img, label = dataset[0]
print(img.shape, label)

import matplotlib
import matplotlib.pyplot as plt

img, label = dataset[0]
print(img.shape, label)
def plotimage(image,label):
  print("image classes:", dataset.classes[label])
  plt.imshow(img.permute(1,2,0))

plotimage(img, label)

img, label = dataset[5001]
print(img.shape, label)
plotimage(img, label)

"""# Training and Validation Datasets

"""

val_size = 5000
train_size = len(dataset) - val_size

train_ds, val_ds = random_split(dataset, [train_size, val_size])
len(train_ds), len(val_ds)

from torch.utils.data.dataloader import DataLoader
batch_size=16
train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=2, pin_memory=True)
val_dl = DataLoader(val_ds, batch_size, num_workers=4, pin_memory=True)

from torchvision.utils import make_grid
for batch in train_dl:
    images,labels=batch
    print('images.shape:', images.shape)
    plt.figure(figsize=(16,8))
    plt.axis('off')
    plt.imshow(make_grid(images, nrow=20).permute((1, 2, 0)))
    break

"""# Model"""

def apply_kernel(image, kernel):
    ri, ci = image.shape       # image dimensions
    rk, ck = kernel.shape      # kernel dimensions
    ro, co = ri-rk+1, ci-ck+1  # output dimensions
    output = torch.zeros([ro, co])
    for i in range(ro): 
        for j in range(co):
            output[i,j] = torch.sum(image[i:i+rk,j:j+ck] * kernel)
    return output
sample_image = torch.tensor([
    [3, 3, 2, 1, 0], 
    [0, 0, 1, 3, 1], 
    [3, 1, 2, 2, 3], 
    [2, 0, 0, 2, 2], 
    [2, 0, 0, 0, 1]
], dtype=torch.float32)

sample_kernel = torch.tensor([
    [0, 1, 2], 
    [2, 2, 0], 
    [0, 1, 2]
], dtype=torch.float32)

print(apply_kernel(sample_image, sample_kernel))
print(sample_image[0:3,0:3])
sample_image[0:3,0:3]*sample_kernel

import torch.nn as nn
import torch.nn.functional as F
conv=nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1)
pool=nn.MaxPool2d(2, 2)
for images, labels in train_dl:
    print('images.shape:', images.shape)
    out = conv(images)
    print('shape:', out.shape)
    out=pool(out)
    print('out.shape:', out.shape)
    break

class CNN_Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2), # output: 64 x 16 x 16

            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2), # output: 128 x 8 x 8

            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2, 2), # output: 256 x 4 x 4

            nn.Flatten(), 
            nn.Linear(256*4*4, 1024),
            nn.ReLU(),
            nn.Linear(1024, 512),
            nn.ReLU(),
            nn.Linear(512, 10))
    def forward(self, xb):
        return self.network(xb)

    def training_step(self,batch):
        images, labels=batch
        out=self(images)
        loss=F.cross_entropy(out, labels)
        return loss

    def validation_step(self,batch):
        images, labels = batch
        out=self(images)
        loss=F.cross_entropy(out, labels)
        acc=accuracy(out, labels)
        return loss, acc
model = CNN_Model()

def accuracy(outputs, labels):
    _, preds = torch.max(outputs, dim=1)
    return torch.tensor(torch.sum(preds == labels).item() / len(preds))

"""# GPU"""

def get_default_device():
    """Pick GPU if available, else CPU"""
    if torch.cuda.is_available():
        return torch.device('cuda')
    else:
        return torch.device('cpu')
    
def to_device(data, device):
    """Move tensor(s) to chosen device"""
    if isinstance(data, (list,tuple)):
        return [to_device(x, device) for x in data]
    return data.to(device, non_blocking=True)

class DeviceDataLoader():
    """Wrap a dataloader to move data to a device"""
    def __init__(self, dl, device):
        self.dl = dl
        self.device = device
        
    def __iter__(self):
        """Yield a batch of data after moving it to device"""
        for b in self.dl: 
            yield to_device(b, self.device)

    def __len__(self):
        """Number of batches"""
        return len(self.dl)

device = get_default_device()
device

train_dl = DeviceDataLoader(train_dl, device)
val_dl = DeviceDataLoader(val_dl, device)

to_device(model, device)

"""# Train the model"""

def fit(epochs, step_size, model, train_loader, val_loader, opt_func=torch.optim.SGD):
    optimizer = opt_func(model.parameters(), step_size) #lr: stepsize
    loss_epoch_res=[]
    acc_epoch_res=[]
    train_epoch_res=[]
    for epoch in range(epochs):
        # Training Phase 
        train_loss=[]
        for batch in train_loader:
            loss = model.training_step(batch)
            train_loss.append(loss)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        loss_result=[]
        accuracy_result=[]
        for batch in val_loader:
            loss, acc=model.validation_step(batch)
            loss_result.append(loss)
            accuracy_result.append(acc)
        avg_train_loss=sum(train_loss)/len(train_loss)
        avg_val_loss=sum(loss_result)/len(loss_result)
        avg_acc=sum(accuracy_result)/len(accuracy_result)
        loss_epoch_res.append(avg_val_loss)
        acc_epoch_res.append(avg_acc)
        train_epoch_res.append(avg_train_loss)
        print("Epoch [{}], train_loss: {:.4f},val_loss: {:.4f}, val_acc: {:.4f}".format(epoch, avg_train_loss,avg_val_loss, avg_acc))
    return train_epoch_res,loss_epoch_res,acc_epoch_res

acc_final_res=[]
train_loss_res=[]
val_loss_res=[]
result1=fit(5, 0.001, model, train_dl, val_dl)
train_loss,val_loss,acc=result1
for item in acc:
  acc_final_res.append(item)
for item in train_loss:
  train_loss_res.append(item)
for item in val_loss:
  val_loss_res.append(item)

result2=fit(5, 0.001, model, train_dl, val_dl)
train_loss,val_loss,acc=result2
for item in acc:
  acc_final_res.append(item)
for item in train_loss:
  train_loss_res.append(item)
for item in val_loss:
  val_loss_res.append(item)

result3=fit(5, 0.001, model, train_dl, val_dl)
train_loss,val_loss,acc=result3
for item in acc:
  acc_final_res.append(item)
for item in train_loss:
  train_loss_res.append(item)
for item in val_loss:
  val_loss_res.append(item)

result4=fit(5, 0.001, model, train_dl, val_dl)
train_loss,val_loss,acc=result4
for item in acc:
  acc_final_res.append(item)
for item in train_loss:
  train_loss_res.append(item)
for item in val_loss:
  val_loss_res.append(item)

result4=fit(5, 0.001, model, train_dl, val_dl)
train_loss,val_loss,acc=result4
for item in acc:
  acc_final_res.append(item)
for item in train_loss:
  train_loss_res.append(item)
for item in val_loss:
  val_loss_res.append(item)

plt.plot(acc_final_res, '-x')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.title('Accuracy vs. No. of epochs');

plt.plot(train_loss_res, '-bx')
plt.plot(val_loss_res, '-rx')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['Training', 'Validation'])
plt.title('Loss vs. No. of epochs');

"""# Prediction"""

test_dataset = ImageFolder(data_dir+'/test', transform=ToTensor())

def predict_image(img, model):
    # Convert to a batch of 1
    xb = to_device(img.unsqueeze(0), device)
    # Get predictions from model
    yb = model(xb)
    # Pick index with highest probability
    _, preds  = torch.max(yb, dim=1)
    # Retrieve the class label
    return dataset.classes[preds[0].item()]

img, label = test_dataset[0]
plt.imshow(img.permute(1, 2, 0))
print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))